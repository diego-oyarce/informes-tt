Se implementó un modelo de autoencoder como parte de una estrategia de aprendizaje no supervisado para predecir y entender el comportamiento del usuario a partir de un conjunto de datos complejo.

\subsection{Preprocesamiento y Preparación de Datos}

Iniciamos con la carga del dataset desde un archivo CSV, seguido por una fase de limpieza de datos para garantizar la calidad del entrenamiento. Se realizaron las siguientes operaciones de preprocesamiento en los datos.

\subsection{Codificación One-Hot}

Para las variables categóricas \textquotedblleft método\textquotedblright y \textquotedblleft canal\textquotedblright, se aplicó una técnica de codificación One-Hot. Esta transformación es crucial para convertir datos categóricos en un formato que pueda ser procesado efectivamente por el modelo de aprendizaje automático. En esta técnica, cada categoría se convierte en una nueva columna, donde la presencia de una categoría específica se marca con un \textquotedblleft 1\textquotedblright, mientras que las demás se marcan con un \textquotedblleft 0\textquotedblright.

\begin{itemize}
    \item \textbf{Normalización de Fechas:} La columna \textquotedblleft fecha\_evento\textquotedblright, que contenía información de fecha y hora, se dividió y estandarizó para asegurar un formato uniforme y utilizable.
    \item \textbf{Eliminación de columnas innecesarias:} Las columnas originales de \textquotedblleft método\textquotedblright y \textquotedblleft canal\textquotedblright se eliminaron después de la codificación, manteniendo el dataset conciso y enfocado en las características relevantes.
    \item \textbf{Transformación Temporal Adicional:} Se llevaron a cabo codificaciones one-hot para las columnas de \textquotedblleft fecha\textquotedblright, \textquotedblleft hora\textquotedblright y \textquotedblleft día de la semana\textquotedblright, ampliando la representatividad de los aspectos temporales de los datos.
\end{itemize}

\begin{figure}[H]
    \begin{minipage}[t]{0.9\textwidth}
        \caption{Preparación y codificación one-hot de los datos}
        \label{codificación_autoencoder}        
    \end{minipage}

    \vspace{10pt}

    \begin{minipage}[b]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/codificación one-hhot.jpg}        
    \end{minipage}

    \begin{minipage}[t]{0.9\textwidth}
        Fuente: Elaboración propia.
    \end{minipage}
\end{figure}


\subsection{Construcción y Entrenamiento del Modelo}

El dataset fue dividido en conjuntos de entrenamiento y validación. Luego, se construyó la arquitectura del autoencoder con capas densas y normalización por lotes, utilizando una función de activación \textquotedblleft tanh\textquotedblright para las capas codificadoras y \textquotedblleft relu\textquotedblright para las decodificadoras. Se implementó un mecanismo de EarlyStopping para prevenir el sobreentrenamiento y mejorar la generalización del modelo.

Un autoencoder es un tipo de red neuronal utilizada en el aprendizaje no supervisado, que tiene como objetivo aprender una representación (codificación) de un conjunto de datos, típicamente para reducción de dimensionalidad, aprendizaje de características, o descompresión de datos. La particularidad de los autoencoders reside en que están diseñados para reconstruir su entrada en la salida, pasando la información a través de una serie de capas que primero comprimen los datos (codificador) y luego los reconstruyen (decodificador).

En el caso de un autoencoder con \textquotedblleft capas densas" (también conocidas como \textquotedblleft capas completamente conectadas"), cada neurona en una capa está conectada a todas las neuronas en la capa siguiente. Este tipo de arquitectura es una de las más comunes en las redes neuronales y es particularmente útil para aprender patrones complejos y no lineales en los datos.

\textbf{Construcción del Codificador:} En la parte del codificador, los datos de entrada pasan a través de capas densas, donde se reduce gradualmente la dimensionalidad. Este proceso se logra reduciendo el número de neuronas en capas sucesivas, obligando así a la red a aprender una representación comprimida de los datos de entrada. Las funciones de activación como \textquotedblleft tanh" (tangente hiperbólica) pueden ser usadas aquí para introducir no linealidades en el modelo, permitiendo que el codificador aprenda representaciones más complejas.

\textbf{Construcción del Decodificador:} La segunda parte del autoencoder es el decodificador, donde la representación comprimida se procesa a través de otras capas densas para reconstruir los datos de entrada. El objetivo es que la salida sea lo más cercana posible a la entrada original. Las funciones de activación como \textquotedblleft relu" (Rectified Linear Unit) son comunes en esta etapa, proporcionando una manera eficiente y efectiva de realizar operaciones no lineales.

\begin{figure}[H]
    \begin{minipage}[t]{0.9\textwidth}
        \caption{Arquitectura del modelo autoencoder}
        \label{arquitectura_autoencoder}        
    \end{minipage}

    \vspace{10pt}

    \begin{minipage}[b]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/Arquitectura modelo autoencoder.jpg}        
    \end{minipage}

    \begin{minipage}[t]{0.9\textwidth}
        Fuente: Elaboración propia.
    \end{minipage}
\end{figure}

El entrenamiento del autoencoder se realizó adoptando un enfoque iterativo y dinámico, donde uno de los aspectos clave fue el monitoreo de la pérdida de validación a lo largo de las iteraciones del entrenamiento, conocidas como "épocas". En el contexto del aprendizaje automático y especialmente en el entrenamiento de redes neuronales, una "época" se refiere a un ciclo completo de pase de todos los datos de entrenamiento a través del modelo.

Una época representa una iteración completa sobre el conjunto de datos de entrenamiento. Durante una época, el modelo procesa cada muestra del conjunto de entrenamiento una vez, permitiendo que el modelo aprenda de los datos. Esto implica que si tenemos un conjunto de datos de entrenamiento con, por ejemplo, 1000 muestras y el modelo se entrena durante 10 épocas, entonces cada muestra habrá sido utilizada 10 veces para ajustar los parámetros del modelo.

Las épocas son fundamentales en el proceso de entrenamiento de un modelo de aprendizaje automático:

\textbf{Aprendizaje Progresivo:} Con cada época, el modelo tiene la oportunidad de aprender y adaptarse a los datos, ajustando sus parámetros (como los pesos en una red neuronal) para minimizar el error o la pérdida.

\textbf{Evaluación y Ajustes:} Al monitorear la pérdida, especialmente la pérdida de validación, al final de cada época, se puede evaluar cómo está aprendiendo el modelo. Si la pérdida de validación deja de mejorar o comienza a aumentar, puede ser una señal de sobreajuste, indicando que el modelo está aprendiendo a memorizar los datos de entrenamiento en lugar de generalizar a partir de ellos.

\textbf{Terminación del Entrenamiento:} El número de épocas también juega un papel crucial en la determinación de cuándo detener el entrenamiento. Demasiadas épocas pueden llevar a sobreajuste, mientras que muy pocas pueden resultar en un modelo subajustado.

\begin{figure}[H]
    \begin{minipage}[t]{0.9\textwidth}
        \caption{Entrenamiento del modelo autoencoder}
        \label{entrenamiento_autoencoder}        
    \end{minipage}

    \vspace{10pt}

    \begin{minipage}[b]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/Entrenamiento autoencoder.jpg}        
    \end{minipage}

    \begin{minipage}[t]{0.9\textwidth}
        Fuente: Elaboración propia.
    \end{minipage}
\end{figure}

\subsection{Resultados y Evaluación}

El modelo final demostró una sólida capacidad de reconstrucción y no mostró signos de sobreajuste, como se evidencia en los gráficos de pérdida de entrenamiento. Este autoencoder está ahora listo para ser utilizado para transformar los datos en una representación de menor dimensión, lo cual facilitará la aplicación de técnicas de clustering para la segmentación de usuarios y la detección de patrones de comportamiento anómalos.

\begin{figure}[H]
    \begin{minipage}[t]{0.9\textwidth}
        \caption{Gráfico del entrenamiento del modelo autoencoder}
        \label{gráfico_autoencoder}        
    \end{minipage}

    \vspace{10pt}

    \begin{minipage}[b]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/Gráfico entrenamiento autoencoder.png}        
    \end{minipage}

    \begin{minipage}[t]{0.9\textwidth}
        Fuente: Elaboración propia.
    \end{minipage}
\end{figure}

\subsection{Conclusión del Modelo de Autoencoder}

El autoencoder se diseñó para transformar datos de alta dimensión en una representación de menor dimensionalidad, lo cual es un paso fundamental en el pre-procesamiento para algoritmos de clustering.

Sin embargo, el propósito inicial del autoencoder no era predecir comportamientos futuros o tendencias, sino más bien identificar patrones intrínsecos y datos atípicos dentro del conjunto de datos existente. Dado que el objetivo central del proyecto es la predicción del comportamiento, se ha determinado que el autoencoder no cumple con los requisitos necesarios para avanzar hacia este nuevo objetivo.

Por tanto, hemos decidido no continuar con el desarrollo e implementación de este modelo en su forma actual. En cambio, nos enfocaremos en la búsqueda y aplicación de modelos predictivos más adecuados que estén alineados con las metas de pronosticar el comportamiento futuro y que puedan ofrecer insights más directos para la toma de decisiones y estrategias proactivas.

Este cambio de dirección subraya la importancia de una alineación clara entre las herramientas de modelado seleccionadas y los objetivos específicos del proyecto. Aunque el autoencoder es una herramienta poderosa para ciertas aplicaciones, en este caso, se ha reconocido que no es la solución óptima para las necesidades proyectadas.

Sin embargo, es importante destacar que el autoencoder es una herramienta extremadamente útil para identificar anomalías en patrones de comportamiento.
